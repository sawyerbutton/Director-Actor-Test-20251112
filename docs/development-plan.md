# å¼€å‘è®¡åˆ’ï¼šå‰§æœ¬åˆ†æç³»ç»Ÿå®ç°æ–¹æ¡ˆ

## ğŸ“‹ ç›®å½•
1. [LangGraphæ¶æ„è®¾è®¡](#langgraphæ¶æ„è®¾è®¡)
2. [TDDæµ‹è¯•é©±åŠ¨å¼€å‘ç­–ç•¥](#tddæµ‹è¯•é©±åŠ¨å¼€å‘ç­–ç•¥)
3. [EDDç¤ºä¾‹é©±åŠ¨å¼€å‘ç­–ç•¥](#eddç¤ºä¾‹é©±åŠ¨å¼€å‘ç­–ç•¥)
4. [éªŒè¯æ ‡å‡†ä¸æˆåŠŸæŒ‡æ ‡](#éªŒè¯æ ‡å‡†ä¸æˆåŠŸæŒ‡æ ‡)
5. [å¼€å‘è·¯çº¿å›¾](#å¼€å‘è·¯çº¿å›¾)

---

## 1. LangGraphæ¶æ„è®¾è®¡

### 1.1 ä¸ºä»€ä¹ˆé€‰æ‹©LangGraphï¼Ÿ

**æ ¸å¿ƒä¼˜åŠ¿**ï¼š
- âœ… çŠ¶æ€æœºç®¡ç†ï¼šæ¸…æ™°çš„çŠ¶æ€æµè½¬ï¼Œæ˜“äºè°ƒè¯•
- âœ… å†…ç½®é‡è¯•æœºåˆ¶ï¼šå¤„ç†LLMè¾“å‡ºä¸ç¨³å®š
- âœ… äººå·¥ä»‹å…¥èŠ‚ç‚¹ï¼šæ”¯æŒå®¡æ ¸æµç¨‹
- âœ… å¯è§†åŒ–ï¼šè‡ªåŠ¨ç”ŸæˆçŠ¶æ€å›¾
- âœ… æŒä¹…åŒ–ï¼šæ”¯æŒcheckpointæ¢å¤

### 1.2 çŠ¶æ€å›¾è®¾è®¡

```mermaid
graph TD
    START[å¼€å§‹] --> VALIDATE_INPUT[éªŒè¯è¾“å…¥]
    VALIDATE_INPUT -->|æœ‰æ•ˆ| STAGE1[Stage1: Discoverer]
    VALIDATE_INPUT -->|æ— æ•ˆ| ERROR[é”™è¯¯å¤„ç†]

    STAGE1 --> VALIDATE_STAGE1[éªŒè¯Stage1è¾“å‡º]
    VALIDATE_STAGE1 -->|é€šè¿‡| STAGE2[Stage2: Auditor]
    VALIDATE_STAGE1 -->|å¤±è´¥| RETRY_STAGE1{é‡è¯•æ¬¡æ•°<3?}
    RETRY_STAGE1 -->|æ˜¯| STAGE1
    RETRY_STAGE1 -->|å¦| HUMAN_REVIEW1[äººå·¥å®¡æ ¸]
    HUMAN_REVIEW1 --> STAGE2

    STAGE2 --> VALIDATE_STAGE2[éªŒè¯Stage2è¾“å‡º]
    VALIDATE_STAGE2 -->|é€šè¿‡| GENERATE_AUDIT[ç”Ÿæˆå®¡è®¡æŠ¥å‘Š]
    VALIDATE_STAGE2 -->|å¤±è´¥| RETRY_STAGE2{é‡è¯•æ¬¡æ•°<3?}
    RETRY_STAGE2 -->|æ˜¯| STAGE2
    RETRY_STAGE2 -->|å¦| HUMAN_REVIEW2[äººå·¥å®¡æ ¸]
    HUMAN_REVIEW2 --> GENERATE_AUDIT

    GENERATE_AUDIT --> STAGE3[Stage3: Modifier]
    STAGE3 --> VALIDATE_STAGE3[éªŒè¯Stage3è¾“å‡º]
    VALIDATE_STAGE3 -->|é€šè¿‡| FINAL_VALIDATION[æœ€ç»ˆéªŒè¯]
    VALIDATE_STAGE3 -->|å¤±è´¥| RETRY_STAGE3{é‡è¯•æ¬¡æ•°<3?}
    RETRY_STAGE3 -->|æ˜¯| STAGE3
    RETRY_STAGE3 -->|å¦| HUMAN_REVIEW3[äººå·¥å®¡æ ¸]
    HUMAN_REVIEW3 --> FINAL_VALIDATION

    FINAL_VALIDATION --> END[å®Œæˆ]
    ERROR --> END
```

### 1.3 çŠ¶æ€å®šä¹‰ï¼ˆState Schemaï¼‰

```python
from typing import TypedDict, List, Optional, Literal
from prompts.schemas import (
    Script, DiscovererOutput, AuditorOutput,
    ModifierOutput, AuditReport
)

class PipelineState(TypedDict):
    """Pipelineçš„å…¨å±€çŠ¶æ€"""

    # è¾“å…¥
    script: Script

    # Stage 1
    discoverer_output: Optional[DiscovererOutput]
    discoverer_retry_count: int
    discoverer_error: Optional[str]

    # Stage 2
    auditor_output: Optional[AuditorOutput]
    auditor_retry_count: int
    auditor_error: Optional[str]

    # Audit Report (Stage 2 -> Stage 3)
    audit_report: Optional[AuditReport]

    # Stage 3
    modifier_output: Optional[ModifierOutput]
    modifier_retry_count: int
    modifier_error: Optional[str]

    # æ§åˆ¶æµ
    current_stage: Literal["validate_input", "stage1", "stage2", "stage3", "complete", "error"]
    requires_human_review: bool
    human_review_message: Optional[str]

    # å…ƒæ•°æ®
    pipeline_start_time: float
    total_llm_calls: int
    total_tokens_used: int
```

### 1.4 èŠ‚ç‚¹å®ç°ï¼ˆNodesï¼‰

#### Node 1: validate_input
```python
def validate_input_node(state: PipelineState) -> PipelineState:
    """éªŒè¯è¾“å…¥çš„Scriptæ˜¯å¦åˆæ³•"""
    try:
        # ä½¿ç”¨PydanticéªŒè¯
        Script.model_validate(state["script"])

        # ä¸šåŠ¡é€»è¾‘éªŒè¯
        errors = validate_setup_payoff_integrity(state["script"])
        if errors:
            logger.warning(f"Setup-payoff integrity issues: {errors}")

        state["current_stage"] = "stage1"
        return state
    except ValidationError as e:
        state["current_stage"] = "error"
        state["discoverer_error"] = f"Invalid input: {e}"
        return state
```

#### Node 2: stage1_discoverer
```python
def stage1_discoverer_node(state: PipelineState) -> PipelineState:
    """æ‰§è¡ŒStage1: è¯†åˆ«TCCs"""

    # åŠ è½½Prompt
    prompt = load_prompt("prompts/stage1_discoverer.md")

    # è°ƒç”¨LLM
    llm = ChatAnthropic(model="claude-sonnet-4-5", temperature=0)
    response = llm.invoke([
        {"role": "system", "content": prompt},
        {"role": "user", "content": state["script"].model_dump_json()}
    ])

    state["total_llm_calls"] += 1
    state["total_tokens_used"] += response.usage_metadata["total_tokens"]

    try:
        # éªŒè¯è¾“å‡º
        output = DiscovererOutput.model_validate_json(response.content)
        state["discoverer_output"] = output
        state["current_stage"] = "stage2"
        logger.info(f"Stage1 success: {len(output.tccs)} TCCs identified")
    except ValidationError as e:
        state["discoverer_retry_count"] += 1
        state["discoverer_error"] = str(e)
        logger.error(f"Stage1 validation failed (retry {state['discoverer_retry_count']}): {e}")

    return state
```

#### Node 3: validate_stage1
```python
def validate_stage1_node(state: PipelineState) -> PipelineState:
    """éªŒè¯Stage1è¾“å‡ºè´¨é‡"""

    if state["discoverer_output"] is None:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
        if state["discoverer_retry_count"] >= 3:
            state["requires_human_review"] = True
            state["human_review_message"] = f"Stage1 failed after 3 retries: {state['discoverer_error']}"
            logger.warning("Stage1 requires human review")
        return state

    # è´¨é‡æ£€æŸ¥
    output = state["discoverer_output"]

    # Check 1: è‡³å°‘æœ‰1ä¸ªTCC
    if len(output.tccs) == 0:
        state["discoverer_output"] = None
        state["discoverer_error"] = "No TCCs identified"
        state["discoverer_retry_count"] += 1
        return state

    # Check 2: Confidenceä¸èƒ½å…¨éƒ¨è¿‡ä½
    avg_confidence = sum(t.confidence for t in output.tccs) / len(output.tccs)
    if avg_confidence < 0.6:
        logger.warning(f"Low average confidence: {avg_confidence}")

    # Check 3: åœºæ™¯å¼•ç”¨æœ‰æ•ˆæ€§
    all_scene_ids = {scene.scene_id for scene in state["script"].scenes}
    for tcc in output.tccs:
        invalid_scenes = [sid for sid in tcc.evidence_scenes if sid not in all_scene_ids]
        if invalid_scenes:
            state["discoverer_output"] = None
            state["discoverer_error"] = f"Invalid scene references: {invalid_scenes}"
            state["discoverer_retry_count"] += 1
            return state

    # é€šè¿‡éªŒè¯
    state["current_stage"] = "stage2"
    return state
```

#### æ¡ä»¶è¾¹ï¼ˆConditional Edgesï¼‰

```python
def should_retry_stage1(state: PipelineState) -> str:
    """å†³å®šæ˜¯å¦é‡è¯•Stage1"""
    if state["discoverer_output"] is not None:
        return "continue"  # æˆåŠŸï¼Œè¿›å…¥ä¸‹ä¸€é˜¶æ®µ

    if state["discoverer_retry_count"] >= 3:
        return "human_review"  # å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œäººå·¥å®¡æ ¸

    return "retry"  # é‡è¯•
```

### 1.5 å®Œæ•´çš„Graphæ„å»º

```python
from langgraph.graph import StateGraph, END

def build_pipeline_graph() -> StateGraph:
    """æ„å»ºå®Œæ•´çš„PipelineçŠ¶æ€å›¾"""

    workflow = StateGraph(PipelineState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("validate_input", validate_input_node)
    workflow.add_node("stage1", stage1_discoverer_node)
    workflow.add_node("validate_stage1", validate_stage1_node)
    workflow.add_node("stage2", stage2_auditor_node)
    workflow.add_node("validate_stage2", validate_stage2_node)
    workflow.add_node("generate_audit", generate_audit_report_node)
    workflow.add_node("stage3", stage3_modifier_node)
    workflow.add_node("validate_stage3", validate_stage3_node)
    workflow.add_node("final_validation", final_validation_node)
    workflow.add_node("human_review", human_review_node)

    # è®¾ç½®å…¥å£
    workflow.set_entry_point("validate_input")

    # æ·»åŠ è¾¹
    workflow.add_edge("validate_input", "stage1")
    workflow.add_edge("stage1", "validate_stage1")

    # æ¡ä»¶è¾¹ï¼šStage1é‡è¯•é€»è¾‘
    workflow.add_conditional_edges(
        "validate_stage1",
        should_retry_stage1,
        {
            "continue": "stage2",
            "retry": "stage1",
            "human_review": "human_review"
        }
    )

    # ç±»ä¼¼åœ°æ·»åŠ Stage2ã€Stage3çš„è¾¹...

    workflow.add_edge("final_validation", END)

    return workflow.compile()
```

---

## 2. TDDæµ‹è¯•é©±åŠ¨å¼€å‘ç­–ç•¥

### 2.1 æµ‹è¯•é‡‘å­—å¡”

```
         /\
        /  \
       / E2E\        5% - ç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆå®Œæ•´Pipelineï¼‰
      /______\
     /        \
    / é›†æˆæµ‹è¯• \    15% - é›†æˆæµ‹è¯•ï¼ˆå¤šä¸ªèŠ‚ç‚¹åä½œï¼‰
   /___________\
  /             \
 /   å•å…ƒæµ‹è¯•    \  80% - å•å…ƒæµ‹è¯•ï¼ˆå•ä¸ªèŠ‚ç‚¹/å‡½æ•°ï¼‰
/________________\
```

### 2.2 å•å…ƒæµ‹è¯•ï¼ˆ80%ï¼‰

#### 2.2.1 SchemaéªŒè¯æµ‹è¯•
```python
# tests/test_schemas.py
import pytest
from prompts.schemas import TCC, DiscovererOutput, ValidationError

class TestTCCSchema:
    """æµ‹è¯•TCCæ•°æ®æ¨¡å‹"""

    def test_valid_tcc(self):
        """æµ‹è¯•æœ‰æ•ˆçš„TCC"""
        tcc = TCC(
            tcc_id="TCC_01",
            super_objective="ç‰é¼ ç²¾'s e-commerce plan",
            core_conflict_type="interpersonal",
            evidence_scenes=["S01", "S02"],
            confidence=0.95
        )
        assert tcc.tcc_id == "TCC_01"

    def test_invalid_tcc_id_format(self):
        """æµ‹è¯•æ— æ•ˆçš„TCC_IDæ ¼å¼"""
        with pytest.raises(ValidationError):
            TCC(
                tcc_id="TCC_1",  # åº”è¯¥æ˜¯TCC_01
                super_objective="test",
                core_conflict_type="interpersonal",
                evidence_scenes=["S01", "S02"],
                confidence=0.95
            )

    def test_invalid_confidence_range(self):
        """æµ‹è¯•confidenceè¶…å‡ºèŒƒå›´"""
        with pytest.raises(ValidationError):
            TCC(
                tcc_id="TCC_01",
                super_objective="test objective",
                core_conflict_type="interpersonal",
                evidence_scenes=["S01", "S02"],
                confidence=1.5  # åº”è¯¥ <= 1.0
            )

    def test_super_objective_length(self):
        """æµ‹è¯•super_objectiveé•¿åº¦é™åˆ¶"""
        with pytest.raises(ValidationError):
            TCC(
                tcc_id="TCC_01",
                super_objective="short",  # åº”è¯¥ >= 10 chars
                core_conflict_type="interpersonal",
                evidence_scenes=["S01", "S02"],
                confidence=0.95
            )
```

#### 2.2.2 Promptè§£ææµ‹è¯•
```python
# tests/test_prompts.py
import pytest
from src.utils.prompt_loader import load_prompt

class TestPromptLoader:
    """æµ‹è¯•PromptåŠ è½½å’Œè§£æ"""

    def test_load_stage1_prompt(self):
        """æµ‹è¯•åŠ è½½Stage1 Prompt"""
        prompt = load_prompt("prompts/stage1_discoverer.md")
        assert "TCC Identification" in prompt
        assert "Output Schema" in prompt

    def test_prompt_file_not_found(self):
        """æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨"""
        with pytest.raises(FileNotFoundError):
            load_prompt("prompts/nonexistent.md")
```

#### 2.2.3 èŠ‚ç‚¹é€»è¾‘æµ‹è¯•ï¼ˆMock LLMï¼‰
```python
# tests/test_nodes.py
import pytest
from unittest.mock import Mock, patch
from src.nodes.discoverer import stage1_discoverer_node
from prompts.schemas import Script, PipelineState

class TestDiscovererNode:
    """æµ‹è¯•DiscovererèŠ‚ç‚¹ï¼ˆMock LLMï¼‰"""

    @pytest.fixture
    def sample_state(self):
        """å‡†å¤‡æµ‹è¯•ç”¨çš„State"""
        return {
            "script": Script(scenes=[...]),
            "discoverer_retry_count": 0,
            "total_llm_calls": 0,
            "total_tokens_used": 0
        }

    @patch("src.nodes.discoverer.ChatAnthropic")
    def test_stage1_success(self, mock_llm, sample_state):
        """æµ‹è¯•Stage1æˆåŠŸåœºæ™¯"""
        # Mock LLMè¿”å›æœ‰æ•ˆJSON
        mock_response = Mock()
        mock_response.content = '''
        {
          "tccs": [
            {
              "tcc_id": "TCC_01",
              "super_objective": "Test objective",
              "core_conflict_type": "interpersonal",
              "evidence_scenes": ["S01", "S02"],
              "confidence": 0.95
            }
          ],
          "metadata": {
            "total_scenes_analyzed": 10,
            "primary_evidence_available": true,
            "fallback_mode": false
          }
        }
        '''
        mock_response.usage_metadata = {"total_tokens": 1000}
        mock_llm.return_value.invoke.return_value = mock_response

        # æ‰§è¡ŒèŠ‚ç‚¹
        result = stage1_discoverer_node(sample_state)

        # éªŒè¯
        assert result["discoverer_output"] is not None
        assert len(result["discoverer_output"].tccs) == 1
        assert result["current_stage"] == "stage2"
        assert result["total_llm_calls"] == 1

    @patch("src.nodes.discoverer.ChatAnthropic")
    def test_stage1_validation_failure(self, mock_llm, sample_state):
        """æµ‹è¯•Stage1è¾“å‡ºéªŒè¯å¤±è´¥"""
        # Mock LLMè¿”å›æ— æ•ˆJSON
        mock_response = Mock()
        mock_response.content = '''{"invalid": "json"}'''
        mock_response.usage_metadata = {"total_tokens": 500}
        mock_llm.return_value.invoke.return_value = mock_response

        result = stage1_discoverer_node(sample_state)

        assert result["discoverer_output"] is None
        assert result["discoverer_retry_count"] == 1
        assert result["discoverer_error"] is not None
```

### 2.3 é›†æˆæµ‹è¯•ï¼ˆ15%ï¼‰

```python
# tests/test_integration.py
import pytest
from src.pipeline import build_pipeline_graph
from prompts.schemas import Script

class TestPipelineIntegration:
    """æµ‹è¯•å¤šä¸ªèŠ‚ç‚¹çš„åä½œ"""

    @pytest.fixture
    def pipeline(self):
        """æ„å»ºPipeline"""
        return build_pipeline_graph()

    def test_stage1_to_stage2_flow(self, pipeline):
        """æµ‹è¯•Stage1åˆ°Stage2çš„æµè½¬"""
        initial_state = {
            "script": load_test_script("examples/simple_script.json"),
            "discoverer_retry_count": 0,
            "auditor_retry_count": 0,
            # ... å…¶ä»–åˆå§‹åŒ–
        }

        # æ‰§è¡Œåˆ°Stage2
        result = pipeline.invoke(initial_state)

        # éªŒè¯Stage1è¾“å‡ºè¢«Stage2æ­£ç¡®æ¥æ”¶
        assert result["discoverer_output"] is not None
        assert result["auditor_output"] is not None
        assert result["auditor_output"].rankings.a_line is not None
```

### 2.4 E2Eæµ‹è¯•ï¼ˆ5%ï¼‰

```python
# tests/test_e2e.py
import pytest
from src.pipeline import ScriptAnalysisPipeline

class TestEndToEnd:
    """ç«¯åˆ°ç«¯æµ‹è¯•"""

    @pytest.mark.slow
    @pytest.mark.requires_llm
    def test_complete_pipeline_simple_script(self):
        """æµ‹è¯•å®Œæ•´Pipelineï¼ˆå•çº¿å‰§æœ¬ï¼‰"""
        # åŠ è½½æµ‹è¯•å‰§æœ¬
        script = load_test_script("examples/single_line_script.json")

        # æ‰§è¡ŒPipeline
        pipeline = ScriptAnalysisPipeline(api_key=TEST_API_KEY)
        result = pipeline.run(script)

        # éªŒè¯æœ€ç»ˆè¾“å‡º
        assert result.discoverer_output is not None
        assert len(result.discoverer_output.tccs) >= 1
        assert result.auditor_output is not None
        assert result.auditor_output.rankings.a_line is not None
        assert result.modifier_output is not None
        assert result.modifier_output.validation.fixed >= 0

    @pytest.mark.slow
    @pytest.mark.requires_llm
    def test_complete_pipeline_complex_script(self):
        """æµ‹è¯•å®Œæ•´Pipelineï¼ˆä¸‰çº¿å‰§æœ¬ï¼‰"""
        script = load_test_script("examples/three_line_script.json")

        pipeline = ScriptAnalysisPipeline(api_key=TEST_API_KEY)
        result = pipeline.run(script)

        # éªŒè¯è¯†åˆ«å‡º3æ¡çº¿
        assert len(result.discoverer_output.tccs) == 3
        assert result.auditor_output.rankings.a_line is not None
        assert len(result.auditor_output.rankings.b_lines) >= 1
```

### 2.5 æµ‹è¯•è¿è¡Œç­–ç•¥

```bash
# å¿«é€Ÿæµ‹è¯•ï¼ˆåªè·‘å•å…ƒæµ‹è¯•ï¼ŒMock LLMï¼‰
pytest tests/ -m "not slow and not requires_llm" --cov=src --cov-report=html

# å®Œæ•´æµ‹è¯•ï¼ˆåŒ…å«é›†æˆå’ŒE2Eï¼Œè°ƒç”¨çœŸå®LLMï¼‰
pytest tests/ --cov=src --cov-report=html

# æŒç»­é›†æˆï¼ˆCIï¼‰ï¼šåªè·‘å¿«é€Ÿæµ‹è¯•
pytest tests/ -m "not requires_llm" --cov=src --cov-report=xml
```

---

## 3. EDDç¤ºä¾‹é©±åŠ¨å¼€å‘ç­–ç•¥

### 3.1 ç¤ºä¾‹å‰§æœ¬é›†ï¼ˆExamples Corpusï¼‰

æˆ‘ä»¬éœ€è¦å‡†å¤‡ä»¥ä¸‹æµ‹è¯•å‰§æœ¬ï¼š

#### Example 1: å•çº¿å‰§æœ¬ï¼ˆsingle_line_script.jsonï¼‰
```json
{
  "name": "å•çº¿å‰§æœ¬ï¼šç®€å•çš„å¯»å®æ•…äº‹",
  "description": "åªæœ‰ä¸€æ¡ä¸»çº¿ï¼Œæ²¡æœ‰å‰¯çº¿",
  "expected_output": {
    "tcc_count": 1,
    "a_line": "ä¸»è§’å¯»æ‰¾å®è—",
    "b_lines": [],
    "c_lines": []
  },
  "scenes": [...]
}
```

#### Example 2: åŒçº¿å‰§æœ¬ï¼ˆdual_line_script.jsonï¼‰
```json
{
  "name": "åŒçº¿å‰§æœ¬ï¼šå¤–éƒ¨å†²çª+å†…éƒ¨å†²çª",
  "expected_output": {
    "tcc_count": 2,
    "a_line": "ä¸»è§’å®Œæˆä»»åŠ¡ï¼ˆå¤–éƒ¨ï¼‰",
    "b_lines": ["ä¸»è§’å…‹æœææƒ§ï¼ˆå†…éƒ¨ï¼‰"]
  }
}
```

#### Example 3: ä¸‰çº¿å‰§æœ¬ï¼ˆthree_line_script.jsonï¼‰
```json
{
  "name": "ä¸‰çº¿å‰§æœ¬ï¼šä¸»çº¿+æƒ…æ„Ÿçº¿+æ¬¡è¦çº¿",
  "expected_output": {
    "tcc_count": 3,
    "a_line": "å•†ä¸šèèµ„è®¡åˆ’",
    "b_lines": ["èº«ä»½è®¤åŒå±æœº"],
    "c_lines": ["å¶åƒå´‡æ‹œç ´ç­"]
  }
}
```

#### Example 4: æ•°æ®ç¼ºå¤±å‰§æœ¬ï¼ˆincomplete_data_script.jsonï¼‰
```json
{
  "name": "æ•°æ®ç¼ºå¤±å‰§æœ¬ï¼š50%åœºæ™¯ç¼ºå°‘setup_payoff",
  "description": "æµ‹è¯•fallbackæœºåˆ¶",
  "expected_output": {
    "fallback_mode": true,
    "tcc_count": ">=1"
  }
}
```

#### Example 5: è¾¹ç•Œcaseå‰§æœ¬ï¼ˆedge_case_script.jsonï¼‰
```json
{
  "name": "è¾¹ç•Œå‰§æœ¬ï¼šä¸¤ä¸ªTCCåˆ†æ•°éå¸¸æ¥è¿‘",
  "description": "æµ‹è¯•A-lineé€‰æ‹©çš„tie-breakingè§„åˆ™",
  "expected_output": {
    "a_line_selection_reason": "drives_climax"
  }
}
```

### 3.2 ç¤ºä¾‹é©±åŠ¨å¼€å‘æµç¨‹

```python
# Step 1: å†™ç¤ºä¾‹ï¼ˆExampleï¼‰
example = {
    "input": load_script("examples/single_line_script.json"),
    "expected": {
        "tcc_count": 1,
        "a_line_present": True,
        "b_lines_count": 0
    }
}

# Step 2: å†™æµ‹è¯•ï¼ˆTestï¼‰
def test_single_line_script():
    pipeline = ScriptAnalysisPipeline()
    result = pipeline.run(example["input"])

    assert len(result.discoverer_output.tccs) == example["expected"]["tcc_count"]
    assert result.auditor_output.rankings.a_line is not None
    assert len(result.auditor_output.rankings.b_lines) == 0

# Step 3: å®ç°ä»£ç ï¼ˆCodeï¼‰
# å®ç°èƒ½é€šè¿‡æµ‹è¯•çš„æœ€å°ä»£ç 

# Step 4: é‡æ„ï¼ˆRefactorï¼‰
# ä»£ç é€šè¿‡åï¼Œé‡æ„ä¼˜åŒ–
```

### 3.3 Golden Datasetï¼ˆé»„é‡‘æ•°æ®é›†ï¼‰

åˆ›å»ºä¸€ä¸ªåŒ…å«äººå·¥æ ‡æ³¨ç­”æ¡ˆçš„æ•°æ®é›†ï¼š

```json
// examples/golden/ç™¾å¦–åˆ›ä¸šæŒ‡å—_ep09.json
{
  "script": {...},
  "human_annotated": {
    "tccs": [
      {
        "tcc_id": "TCC_01",
        "super_objective": "ç‰é¼ ç²¾çš„ç”µå•†èèµ„è®¡åˆ’",
        "core_conflict_type": "interpersonal",
        "evidence_scenes": ["S03", "S04", "S05", "S10", "S12"],
        "confidence": 0.95,
        "annotator": "ä¸“ä¸šç¼–å‰§A",
        "notes": "ä¸»è¦é©±åŠ¨æ•´ä¸ªå‰§æƒ…"
      }
    ],
    "rankings": {
      "a_line": "TCC_01",
      "b_lines": ["TCC_02"],
      "c_lines": ["TCC_03"]
    },
    "issues_found": [
      {
        "issue_id": "ISS_001",
        "scene": "S20",
        "description": "S10è®¾ç½®äº†ä¼ç¬”ä½†S20æœªæ”¶å›"
      }
    ]
  }
}
```

**ç”¨é€”**ï¼š
1. å›å½’æµ‹è¯•ï¼šæ¯æ¬¡ä¿®æ”¹åå¯¹æ¯”Golden Dataset
2. æ€§èƒ½è¯„ä¼°ï¼šè®¡ç®—å‡†ç¡®ç‡ã€å¬å›ç‡
3. A/Bæµ‹è¯•ï¼šå¯¹æ¯”ä¸åŒPromptç‰ˆæœ¬

---

## 4. éªŒè¯æ ‡å‡†ä¸æˆåŠŸæŒ‡æ ‡

### 4.1 åŠŸèƒ½æ­£ç¡®æ€§æŒ‡æ ‡

#### Stage 1 (Discoverer)
| æŒ‡æ ‡ | ç›®æ ‡ | æµ‹é‡æ–¹æ³• |
|------|------|---------|
| TCCè¯†åˆ«å‡†ç¡®ç‡ | â‰¥85% | å¯¹æ¯”Golden Dataset |
| åé•œåƒæˆåŠŸç‡ | 100% | ä¸åº”å‡ºç°é•œåƒTCC |
| Fallbackè§¦å‘ç‡ | â‰¤20% | å¤§éƒ¨åˆ†å‰§æœ¬åº”æœ‰å®Œæ•´æ•°æ® |
| Confidenceå‡å€¼ | â‰¥0.75 | å¹³å‡ç½®ä¿¡åº¦ |

#### Stage 2 (Auditor)
| æŒ‡æ ‡ | ç›®æ ‡ | æµ‹é‡æ–¹æ³• |
|------|------|---------|
| A-lineé€‰æ‹©æ­£ç¡®ç‡ | â‰¥90% | å¯¹æ¯”äººå·¥æ ‡æ³¨ |
| B-lineè¯†åˆ«F1-score | â‰¥0.80 | ç²¾ç¡®ç‡+å¬å›ç‡ |
| è¯„åˆ†å…¬å¼ä¸€è‡´æ€§ | 100% | ç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒåˆ†æ•° |

#### Stage 3 (Modifier)
| æŒ‡æ ‡ | ç›®æ ‡ | æµ‹é‡æ–¹æ³• |
|------|------|---------|
| Issueä¿®å¤ç‡ | â‰¥85% | fixed / total_issues |
| æ— å‰¯ä½œç”¨ç‡ | 100% | new_issues_introduced == 0 |
| Setup-payoffä¿®å¤ç‡ | â‰¥90% | æœ€å¸¸è§çš„é—®é¢˜ç±»å‹ |

### 4.2 æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡ | æµ‹é‡æ–¹æ³• |
|------|------|---------|
| ç«¯åˆ°ç«¯è€—æ—¶ | <120s | 50åœºæ™¯å‰§æœ¬ |
| LLMè°ƒç”¨æ¬¡æ•° | â‰¤5æ¬¡ | ç†æƒ³æƒ…å†µï¼š3æ¬¡ï¼ˆæ— é‡è¯•ï¼‰ |
| Tokenä½¿ç”¨é‡ | <50K tokens | 50åœºæ™¯å‰§æœ¬ |
| å†…å­˜å ç”¨ | <500MB | å³°å€¼å†…å­˜ |

### 4.3 é²æ£’æ€§æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡ | æµ‹é‡æ–¹æ³• |
|------|------|---------|
| æ•°æ®ç¼ºå¤±å®¹é”™ç‡ | 100% | ä¸åº”crash |
| é‡è¯•æˆåŠŸç‡ | â‰¥70% | retryåæˆåŠŸçš„æ¯”ä¾‹ |
| å¼‚å¸¸æ¢å¤ç‡ | 100% | æ‰€æœ‰å¼‚å¸¸éƒ½åº”è¢«æ•è· |
| äººå·¥å®¡æ ¸è§¦å‘ç‡ | â‰¤5% | å¤§éƒ¨åˆ†åº”è‡ªåŠ¨å®Œæˆ |

### 4.4 å¯è§‚æµ‹æ€§æŒ‡æ ‡

**å¿…é¡»è®°å½•çš„æ•°æ®**ï¼š
- æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œæ—¶é—´
- æ¯æ¬¡LLMè°ƒç”¨çš„è¾“å…¥è¾“å‡ºï¼ˆLangSmithï¼‰
- æ¯ä¸ªvalidationçš„é€šè¿‡/å¤±è´¥åŸå› 
- é‡è¯•æ¬¡æ•°å’ŒåŸå› 
- äººå·¥å®¡æ ¸çš„è§¦å‘åŸå› 

**Dashboard**ï¼š
```
Pipelineæ‰§è¡Œæ‘˜è¦:
â”œâ”€ æ€»è€—æ—¶: 85s
â”œâ”€ LLMè°ƒç”¨: 3æ¬¡
â”œâ”€ Tokenä½¿ç”¨: 28,500
â”œâ”€ é‡è¯•æ¬¡æ•°: 0
â”œâ”€ äººå·¥å®¡æ ¸: å¦
â””â”€ æœ€ç»ˆç»“æœ: æˆåŠŸ

å„é˜¶æ®µè€—æ—¶:
â”œâ”€ Stage1 (Discoverer): 25s
â”œâ”€ Stage2 (Auditor): 30s
â””â”€ Stage3 (Modifier): 20s
```

### 4.5 éªŒè¯æµç¨‹

```python
# éªŒè¯è„šæœ¬
def validate_system():
    """è¿è¡Œå®Œæ•´éªŒè¯"""

    results = {
        "functional": validate_functional_correctness(),
        "performance": validate_performance(),
        "robustness": validate_robustness()
    }

    # ç”ŸæˆæŠ¥å‘Š
    report = generate_validation_report(results)

    # é€šè¿‡æ ‡å‡†
    if all([
        results["functional"]["discoverer_accuracy"] >= 0.85,
        results["functional"]["auditor_a_line_accuracy"] >= 0.90,
        results["functional"]["modifier_fix_rate"] >= 0.85,
        results["performance"]["avg_time"] <= 120,
        results["robustness"]["crash_rate"] == 0
    ]):
        print("âœ… ç³»ç»ŸéªŒè¯é€šè¿‡")
        return True
    else:
        print("âŒ ç³»ç»ŸéªŒè¯å¤±è´¥")
        print(report)
        return False
```

---

## 5. å¼€å‘è·¯çº¿å›¾

### Phase 1: åŸºç¡€è®¾æ–½ï¼ˆWeek 1ï¼‰
**ç›®æ ‡**ï¼šæ­å»ºå¯è¿è¡Œçš„éª¨æ¶

- [ ] **Day 1-2**: åˆ›å»ºé¡¹ç›®ç»“æ„
  - åˆ›å»ºsrc/ç›®å½•ç»“æ„
  - é…ç½®pytest
  - é…ç½®pre-commit hooks
  - ç¼–å†™.gitignore

- [ ] **Day 3-4**: å®ç°åŸºç¡€å·¥å…·ç±»
  - PromptLoaderï¼ˆåŠ è½½Promptæ–‡ä»¶ï¼‰
  - LLMClientï¼ˆå°è£…Anthropic APIè°ƒç”¨ï¼‰
  - Loggerï¼ˆç»“æ„åŒ–æ—¥å¿—ï¼‰

- [ ] **Day 5**: åˆ›å»ºæµ‹è¯•ç¤ºä¾‹
  - å‡†å¤‡5ä¸ªæµ‹è¯•å‰§æœ¬JSON
  - ç¼–å†™SchemaéªŒè¯æµ‹è¯•
  - æµ‹è¯•è¦†ç›–ç‡>80%

**äº¤ä»˜ç‰©**ï¼š
- âœ… å¯è¿è¡Œçš„æµ‹è¯•å¥—ä»¶
- âœ… 5ä¸ªæµ‹è¯•å‰§æœ¬
- âœ… åŸºç¡€å·¥å…·ç±»

**éªŒè¯æ ‡å‡†**ï¼š
```bash
pytest tests/ -v
# æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ˆè™½ç„¶åŠŸèƒ½è¿˜æ˜¯ç©ºçš„ï¼‰
```

### Phase 2: Stage 1 å®ç°ï¼ˆWeek 2ï¼‰
**ç›®æ ‡**ï¼šå®ç°å¹¶æµ‹è¯•Discoverer

- [ ] **Day 1-2**: TDDå®ç°DiscovererNode
  - å…ˆå†™æµ‹è¯•ï¼ˆmock LLMï¼‰
  - å®ç°èŠ‚ç‚¹é€»è¾‘
  - å®ç°éªŒè¯é€»è¾‘

- [ ] **Day 3**: é›†æˆçœŸå®LLMæµ‹è¯•
  - ç”¨5ä¸ªæµ‹è¯•å‰§æœ¬è¿è¡Œ
  - è°ƒè¯•Promptï¼ˆå¦‚æœå‡†ç¡®ç‡<85%ï¼‰
  - è®°å½•é—®é¢˜å¹¶ä¼˜åŒ–

- [ ] **Day 4-5**: é‡è¯•å’Œå®¹é”™æœºåˆ¶
  - å®ç°é‡è¯•é€»è¾‘
  - å®ç°fallbackæœºåˆ¶
  - æµ‹è¯•è¾¹ç•Œæ¡ä»¶

**äº¤ä»˜ç‰©**ï¼š
- âœ… DiscovererNodeå®Œæ•´å®ç°
- âœ… å•å…ƒæµ‹è¯•è¦†ç›–ç‡>90%
- âœ… åœ¨Golden Datasetä¸Šå‡†ç¡®ç‡â‰¥85%

**éªŒè¯æ ‡å‡†**ï¼š
```python
# æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡
pytest tests/test_discoverer.py -v

# Golden DatasetéªŒè¯
python scripts/validate_discoverer.py
# Output: Accuracy: 87% âœ…
```

### Phase 3: Stage 2 å®ç°ï¼ˆWeek 3ï¼‰
**ç›®æ ‡**ï¼šå®ç°å¹¶æµ‹è¯•Auditor

- [ ] **Day 1-2**: TDDå®ç°AuditorNode
  - å®ç°è¯„åˆ†å…¬å¼
  - å®ç°æ’åºé€»è¾‘
  - å®ç°Forcesåˆ†æ

- [ ] **Day 3**: é›†æˆæµ‹è¯•
  - Stage1 -> Stage2æµè½¬
  - éªŒè¯A-lineé€‰æ‹©æ­£ç¡®æ€§
  - ä¼˜åŒ–è¯„åˆ†æƒé‡

- [ ] **Day 4-5**: Edge caseå¤„ç†
  - åªæœ‰1ä¸ªTCC
  - ä¸¤ä¸ªTCCåˆ†æ•°ç›¸åŒ
  - æ²¡æœ‰æ˜æ˜¾B-line

**äº¤ä»˜ç‰©**ï¼š
- âœ… AuditorNodeå®Œæ•´å®ç°
- âœ… A-lineé€‰æ‹©æ­£ç¡®ç‡â‰¥90%
- âœ… B-line F1-scoreâ‰¥0.80

### Phase 4: Stage 3 å®ç°ï¼ˆWeek 4ï¼‰
**ç›®æ ‡**ï¼šå®ç°å¹¶æµ‹è¯•Modifier

- [ ] **Day 1-3**: TDDå®ç°ModifierNode
  - å®ç°å„ç±»Issueçš„fixé€»è¾‘
  - å®ç°modification log
  - å®ç°å†²çªå¤„ç†

- [ ] **Day 4**: ç”ŸæˆAudit Report
  - ä»Stage2è¾“å‡ºæ¨æ–­Issues
  - å®ç°Issueç”Ÿæˆé€»è¾‘

- [ ] **Day 5**: éªŒè¯å’Œä¼˜åŒ–
  - æµ‹è¯•ä¿®å¤ç‡
  - ç¡®ä¿æ— å‰¯ä½œç”¨

**äº¤ä»˜ç‰©**ï¼š
- âœ… ModifierNodeå®Œæ•´å®ç°
- âœ… Issueä¿®å¤ç‡â‰¥85%
- âœ… æ— å‰¯ä½œç”¨ç‡100%

### Phase 5: Pipelineé›†æˆï¼ˆWeek 5ï¼‰
**ç›®æ ‡**ï¼šå®Œæ•´çš„LangGraph Pipeline

- [ ] **Day 1-2**: æ„å»ºStateGraph
  - å®ç°æ‰€æœ‰èŠ‚ç‚¹
  - å®ç°æ¡ä»¶è¾¹
  - å®ç°äººå·¥å®¡æ ¸èŠ‚ç‚¹ï¼ˆå¯é€‰ï¼‰

- [ ] **Day 3-4**: E2Eæµ‹è¯•
  - 5ä¸ªæµ‹è¯•å‰§æœ¬å®Œæ•´è¿è¡Œ
  - æ€§èƒ½æµ‹è¯•
  - é²æ£’æ€§æµ‹è¯•

- [ ] **Day 5**: å¯è§‚æµ‹æ€§
  - é›†æˆLangSmith
  - æ·»åŠ è¯¦ç»†æ—¥å¿—
  - ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š

**äº¤ä»˜ç‰©**ï¼š
- âœ… å®Œæ•´çš„Pipeline
- âœ… E2Eæµ‹è¯•é€šè¿‡
- âœ… å¯è§‚æµ‹æ€§é›†æˆ

**éªŒè¯æ ‡å‡†**ï¼š
```python
# å®Œæ•´Pipelineæµ‹è¯•
pytest tests/test_e2e.py -v --requires-llm

# æ€§èƒ½æµ‹è¯•
python scripts/benchmark.py
# Output: å¹³å‡è€—æ—¶: 92s âœ…
```

### Phase 6: ä¼˜åŒ–ä¸äº¤ä»˜ï¼ˆWeek 6ï¼‰
**ç›®æ ‡**ï¼šä¼˜åŒ–æ€§èƒ½ï¼Œå‡†å¤‡äº¤ä»˜

- [ ] **Day 1-2**: æ€§èƒ½ä¼˜åŒ–
  - Promptå‹ç¼©ï¼ˆå‡å°‘tokenï¼‰
  - å¹¶è¡ŒåŒ–ï¼ˆå¦‚æœå¯èƒ½ï¼‰
  - ç¼“å­˜æœºåˆ¶

- [ ] **Day 3**: æ–‡æ¡£å®Œå–„
  - APIæ–‡æ¡£
  - ä½¿ç”¨ç¤ºä¾‹
  - æ•…éšœæ’é™¤æŒ‡å—

- [ ] **Day 4-5**: Golden DatasetéªŒè¯
  - åœ¨10ä¸ªäººå·¥æ ‡æ³¨å‰§æœ¬ä¸ŠéªŒè¯
  - ç”ŸæˆéªŒè¯æŠ¥å‘Š
  - ä¸ä¸šåŠ¡å›¢é˜Ÿreview

**äº¤ä»˜ç‰©**ï¼š
- âœ… æ€§èƒ½è¾¾æ ‡ï¼ˆ<120sï¼‰
- âœ… å®Œæ•´æ–‡æ¡£
- âœ… éªŒè¯æŠ¥å‘Š

---

## 6. æŒç»­é›†æˆé…ç½®

```yaml
# .github/workflows/ci.yml
name: CI

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov

      - name: Run unit tests (no LLM)
        run: |
          pytest tests/ -m "not requires_llm" --cov=src --cov-report=xml

      - name: Upload coverage
        uses: codecov/codecov-action@v2
        with:
          file: ./coverage.xml
```

---

## 7. é£é™©è¯„ä¼°ä¸ç¼“è§£

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|------|---------|
| LLMè¾“å‡ºä¸ç¨³å®š | é«˜ | é«˜ | é‡è¯•æœºåˆ¶+æ¸©åº¦å‚æ•°=0 |
| Golden Datasetä¸è¶³ | ä¸­ | é«˜ | æå‰å‡†å¤‡10ä¸ªæ ‡æ³¨å‰§æœ¬ |
| æ€§èƒ½ä¸è¾¾æ ‡ | ä¸­ | ä¸­ | Promptä¼˜åŒ–+å¹¶è¡ŒåŒ– |
| Promptéœ€è¦é¢‘ç¹è°ƒæ•´ | é«˜ | ä¸­ | ç‰ˆæœ¬æ§åˆ¶+A/Bæµ‹è¯• |
| äººå·¥å®¡æ ¸æµç¨‹ä¸æ˜ç¡® | ä½ | ä½ | å…ˆå®ç°è‡ªåŠ¨åŒ–ï¼Œåç»­åŠ å®¡æ ¸ |

---

## æ€»ç»“

### ä¸ºä»€ä¹ˆè¿™ä¸ªæ–¹æ¡ˆå¯è¡Œï¼Ÿ

1. **LangGraphçš„ä¼˜åŠ¿**ï¼š
   - çŠ¶æ€ç®¡ç†æ¸…æ™°
   - é‡è¯•æœºåˆ¶å†…ç½®
   - å¯è§†åŒ–è°ƒè¯•
   - æ”¯æŒäººå·¥ä»‹å…¥

2. **TDDä¿è¯è´¨é‡**ï¼š
   - æµ‹è¯•å…ˆè¡Œ
   - é«˜è¦†ç›–ç‡
   - å¿«é€Ÿåé¦ˆ

3. **EDDä¿è¯å®ç”¨**ï¼š
   - ç¤ºä¾‹é©±åŠ¨
   - Golden DatasetéªŒè¯
   - çœŸå®åœºæ™¯æµ‹è¯•

4. **æ˜ç¡®çš„éªŒè¯æ ‡å‡†**ï¼š
   - åŠŸèƒ½ã€æ€§èƒ½ã€é²æ£’æ€§ä¸‰ç»´åº¦
   - é‡åŒ–æŒ‡æ ‡
   - è‡ªåŠ¨åŒ–éªŒè¯

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

å¦‚æœä½ è®¤å¯è¿™ä¸ªæ–¹æ¡ˆï¼Œæˆ‘ä»¬å¯ä»¥ï¼š
1. **Phase 1ï¼ˆæœ¬å‘¨ï¼‰**ï¼šæ­å»ºåŸºç¡€è®¾æ–½
2. **Phase 2ï¼ˆä¸‹å‘¨ï¼‰**ï¼šå®ç°Stage 1

**ç¬¬ä¸€ä¸ªå…·ä½“ä»»åŠ¡**ï¼š
- åˆ›å»º5ä¸ªæµ‹è¯•å‰§æœ¬JSON
- ç¼–å†™pytesté…ç½®
- å®ç°PromptLoaderå·¥å…·ç±»

ä½ è§‰å¾—è¿™ä¸ªæ–¹æ¡ˆå¦‚ä½•ï¼Ÿæœ‰å“ªäº›åœ°æ–¹éœ€è¦è°ƒæ•´ï¼Ÿ
