# Claude Code Reference Documentation

This file provides quick navigation to all project documentation for AI-assisted development.

## Project Overview

**Name**: å‰§æœ¬å™äº‹ç»“æ„åˆ†æç³»ç»Ÿ (Script Narrative Structure Analysis System)

**Purpose**: Multi-agent LLM system for analyzing and correcting narrative structure in screenplays using a three-stage pipeline (Discover â†’ Audit â†’ Modify).

**Technology Stack**: Python, LangChain, LangGraph, Pydantic, DeepSeek/Claude/OpenAI

**Current Version**: 2.4.1 (2025-11-14)
**Last Updated**: 2025-11-14
**Completion**: 100% (All three stages + TXT Parser + Web UI + Mermaid Visualization + LangSmith observability + A/B testing + Markdown export)

---

## Quick Start

### For First-Time Users
1. Read: [`ref/getting-started.md`](ref/getting-started.md) - Installation, setup, and basic usage
2. Run: `pip install -r requirements.txt` - Install dependencies (âœ… Done)
3. Configure: Copy `.env.example` to `.env` and add your DeepSeek API key (âœ… Done)
4. Run: `pytest tests/ -v` - Verify installation (âœ… 44/44 tests passing)
5. Try: `python -m src.cli analyze examples/golden/ç™¾å¦–_ep09_s01-s05.json` (âœ… All stages working)

### For Developers
1. Read: [`ref/architecture.md`](ref/architecture.md) - System design and components
2. Read: [`prompts/README.md`](prompts/README.md) - Prompt engineering guide
3. Review: [`tests/`](tests/) - Test examples

---

## Current Status (2025-11-14)

### âœ… What's Working (100% Complete)
- **Unit Tests**: 44/44 passing (100% pass rate)
- **Stage 1 (Discoverer)**: âœ… Successfully identifies TCCs with 85-95% confidence
- **Stage 2 (Auditor)**: âœ… Ranks TCCs as A/B/C-lines with proper scoring
- **Stage 3 (Modifier)**: âœ… Fixes structural issues with normalized issue_id validation
- **Dependencies**: All packages installed (LangChain 1.0.5, LangGraph 1.0.3, LangSmith 0.1+)
- **DeepSeek Integration**: Configured and operational
- **Documentation**: Complete reference docs (120KB+ across 15+ files)
- **Error Handling**: Intelligent JSON parsing and schema validation with 0 retries
- **ğŸ†• TXT Script Parser** (v2.4.0): âœ… Convert TXT scripts to JSON (Phase 1-3 complete)
- **ğŸ†• LLM Enhancement**: âœ… Semantic extraction with async progress callbacks
- **ğŸ†• Web UI Integration**: âœ… TXT upload, preview, continue-to-analysis workflow
- **ğŸ†• Mermaid Visualization** (v2.4.1): âœ… Interactive TCC relationship diagrams with A/B/C color coding
- **LangSmith Observability**: âœ… Auto-tracing, performance metrics, cost estimation
- **A/B Testing Framework**: âœ… Compare providers, prompts, and parameters
- **Markdown Export** (v2.3.0): âœ… Professional reports + Mermaid visualization

### ğŸ‰ Recent Fixes (2025-11-14)

#### Session 8: UX Optimization & Bug Fixes
1. **Stage 3 issue_id Validation** (âœ… FIXED - Session 8)
   - **Problem**: LLM returns `ISS_001_corrected`, `ISS_002_fixed` not matching `^ISS_\d{3}$` pattern
   - **Solution**: Added `normalize_issue_id()` validator to extract ISS_XXX pattern
   - **Location**: `prompts/schemas.py:260-273`
   - **Result**: First attempt success, no retries needed, accurate modification counts

2. **Mermaid Visualization Not Rendering** (âœ… FIXED - Session 8)
   - **Problem**: Visualization tab shows only code text, not rendered diagram
   - **Solution**:
     - Upgraded to Mermaid 10+ API: `mermaid.render()` instead of deprecated `mermaid.init()`
     - Changed initialization: `startOnLoad: false` to allow dynamic rendering
   - **Location**: `static/js/results.js:348-382`, `templates/results.html:5-16`
   - **Result**: Correct display of colored TCC relationship diagrams (A-line yellow, B-line blue, C-line gray)

3. **TXT Parser Event Loop Error** (âœ… FIXED - Session 8)
   - **Problem**: `RuntimeError: no running event loop` during TXT upload
   - **Solution**:
     - Converted `LLMEnhancedParser.parse()` to async method
     - Properly await async parser in `run_parsing_job()`
   - **Location**: `src/parser/llm_enhancer.py:82-125`, `src/web/app.py:560-567`
   - **Result**: TXT parsing works correctly, progress callbacks trigger properly

#### Session 7: Web UI Foundation
4. **Stage 2 JSON Parsing** (âœ… FIXED - Session 7)
   - **Solution**: Enhanced `clean_json_response()` with bracket-stack matching algorithm
   - **Location**: `src/pipeline.py:155-215`
   - **Result**: Extracts first complete JSON object, ignoring trailing text

5. **Stage 3 change_type Validation** (âœ… FIXED - Session 7)
   - **Solution**: Extended allowed values and added normalization validator
   - **Location**: `prompts/schemas.py:275-289`
   - **Result**: Supports "remove" and "delete" operations with smart normalization

6. **Web UI WebSocket Serialization** (âœ… FIXED - Session 7)
   - **Problem**: WebSocket couldn't send Script objects in progress updates
   - **Solution**: Restructured to send only serializable summary data
   - **Location**: `src/web/app.py:408-441`
   - **Result**: Real-time progress updates working correctly

7. **Frontend Data Structure Mismatch** (âœ… FIXED - Session 7)
   - **Problem**: JavaScript expected flat fields, backend returns nested `reasoning` object
   - **Solution**: Modified frontend to use optional chaining for nested fields
   - **Location**: `static/js/results.js:252-278`
   - **Result**: Results page displays correctly without JavaScript errors

### ğŸ“Š Test Results Summary
```bash
# Unit Tests
pytest tests/ -v
# Result: 44 passed, 3 skipped (LLM integration tests)
# Status: âœ… 100% pass rate

# Complete Pipeline Test (End-to-End)
python -m src.cli analyze examples/golden/ç™¾å¦–_ep09_s01-s05.json
# Stage 1: âœ… Success (3 TCCs identified with 0.80-0.95 confidence)
# Stage 2: âœ… Success (A-line: TCC_01, B-line: TCC_02, C-line: TCC_03)
# Stage 3: âœ… Success (4/4 issues fixed: removed invalid scene references)
# Errors: 0
# Retries: 0
# Status: âœ… Production Ready
```

### ğŸ¯ System Status
**Status**: âœ… **Production Ready**
- All three stages operational
- Zero-retry success rate
- Comprehensive error handling
- Complete documentation
- Ready for real-world screenplay analysis

---

## Core Documentation

### 1. Project Overview
**File**: [`ref/project-overview.md`](ref/project-overview.md)

**Contents**:
- Project description and goals
- Key features and capabilities
- Technology stack
- Project status and metrics

**When to read**: Getting context about the project

---

### 2. Architecture
**File**: [`ref/architecture.md`](ref/architecture.md)

**Contents**:
- Director-Actor pattern design
- Three-stage pipeline explanation
- Data flow diagrams
- Component descriptions
- Error handling strategies
- LLM provider integration

**When to read**: Understanding system design, extending functionality

**Key sections**:
- Three-Stage Pipeline (lines 13-90)
- Data Flow (lines 92-125)
- Error Handling (lines 183-203)

---

### 3. Getting Started
**File**: [`ref/getting-started.md`](ref/getting-started.md)

**Contents**:
- Installation instructions
- API key setup
- Basic usage examples
- Configuration guide
- Common workflows
- Troubleshooting

**When to read**: First-time setup, configuration issues

**Key sections**:
- Quick Start (lines 5-35)
- API Key Setup (lines 60-96)
- Common Workflows (lines 182-261)

---

### 4. API Reference
**File**: [`ref/api-reference.md`](ref/api-reference.md)

**Contents**:
- Complete function signatures
- Parameter descriptions
- Return types
- Usage examples
- CLI commands
- Data models
- Validation functions
- Environment variables

**When to read**: Writing code, API integration

**Key sections**:
- Core Functions (lines 7-138)
- Data Models (lines 176-265)
- Validation Functions (lines 267-336)
- Calculation Functions (lines 338-407)

---

### 5. Testing Guide
**File**: [`ref/testing.md`](ref/testing.md)

**Contents**:
- Test structure overview
- Running tests
- Test categories (unit, integration, benchmarks)
- Test-driven development workflow
- Mocking strategies
- Coverage reporting
- CI/CD integration

**When to read**: Writing tests, debugging test failures

**Key sections**:
- Running Tests (lines 17-51)
- Schema Tests (lines 55-123)
- Golden Dataset Tests (lines 127-195)
- Benchmarks (lines 199-263)

---

### 6. Prompts Guide
**File**: [`ref/prompts-guide.md`](ref/prompts-guide.md)

**Contents**:
- Prompt architecture overview
- Stage-by-stage breakdown
- Prompt engineering best practices
- Customization strategies
- Testing prompts
- Versioning and migration

**When to read**: Modifying prompts, adding new stages

**Key sections**:
- Stage 1: Discoverer (lines 41-156)
- Stage 2: Auditor (lines 160-293)
- Stage 3: Modifier (lines 297-395)
- Customizing Prompts (lines 499-599)

---

### 7. TXT Script Parser Guide
**File**: [`ref/txt-parser-guide.md`](ref/txt-parser-guide.md)

**Contents**:
- TXT to JSON conversion system
- Three-phase development (Basic Parser â†’ LLM Enhancement â†’ Web Integration)
- Parser architecture and implementation
- TXT format requirements
- Web UI workflow
- API reference
- Performance characteristics
- Troubleshooting guide

**When to read**: Working with TXT scripts, integrating parser, understanding Web upload flow

**Key sections**:
- Phase 1: Basic TXT Parser - Rule-based parsing
- Phase 2: LLM Enhancement - Semantic extraction
- Phase 3: Web Integration - Upload and preview workflow
- TXT Format Requirements - How to format scripts
- API Reference - Using parsers programmatically
- Testing - Automated test suite
- Performance - Timing and cost analysis

---

## Important Files

### Source Code

#### Core Implementation
- **[`src/pipeline.py`](src/pipeline.py)** (18,954 bytes)
  - LangGraph pipeline
  - Actor implementations (DiscovererActor, AuditorActor, ModifierActor)
  - LLM provider integration
  - State management
  - **Start here for**: Pipeline logic, actor behavior

- **[`src/cli.py`](src/cli.py)** (11,500+ bytes)
  - Command-line interface
  - Commands: analyze, validate, benchmark, ab-test
  - **Start here for**: CLI usage, command implementation

- **[`src/monitoring.py`](src/monitoring.py)** (12,000+ bytes)
  - Metrics storage and analysis
  - Cost estimation utilities
  - Performance tracking
  - **Start here for**: Observability, cost tracking

- **[`src/ab_testing.py`](src/ab_testing.py)** (16,000+ bytes)
  - A/B testing framework
  - Variant comparison
  - Automated evaluation
  - **Start here for**: Testing different configurations

#### ğŸ†• TXT Script Parser (v2.4.0)
- **[`src/parser/base.py`](src/parser/base.py)** (80 lines)
  - Abstract base class for all parsers
  - Defines parse() and validate_output() interface
  - **Start here for**: Understanding parser architecture

- **[`src/parser/txt_parser.py`](src/parser/txt_parser.py)** (320 lines)
  - Basic rule-based TXT parser (Phase 1)
  - Scene splitting, character extraction
  - Multi-format scene header support
  - **Start here for**: Basic TXT parsing logic

- **[`src/parser/llm_enhancer.py`](src/parser/llm_enhancer.py)** (450 lines)
  - LLM-enhanced parser (Phase 2)
  - Semantic extraction (scene mission, key events, etc.)
  - 5 LLM prompts for semantic understanding
  - **Start here for**: LLM enhancement logic

- **[`src/parser/prompts/`](src/parser/prompts/)** (5 files, 11,500+ characters)
  - scene_mission_prompt.md - Extract scene objectives
  - key_events_prompt.md - Identify important events
  - setup_payoff_prompt.md - Find causal relationships
  - relation_change_prompt.md - Track character relations
  - info_change_prompt.md - Track information reveals
  - **Start here for**: Understanding LLM prompts

- **[`src/web/app.py`](src/web/app.py)** (Updated with ~200 lines)
  - TXT upload endpoint: `/api/parse-txt`
  - Preview page route: `/parse-preview/{job_id}`
  - Continue-to-analysis: `/analysis-from-parsed/{job_id}`
  - Background parsing task with WebSocket progress
  - **Start here for**: Web integration logic

- **[`templates/parse_preview.html`](templates/parse_preview.html)** (290 lines)
  - Parse preview interface
  - 4-tab layout (Overview, Scenes, Characters, Raw JSON)
  - WebSocket progress tracking
  - Continue and download buttons
  - **Start here for**: Preview UI implementation

- **[`static/js/upload.js`](static/js/upload.js)** (165 lines, rewritten)
  - Smart routing based on file type
  - TXT â†’ parse preview flow
  - JSON â†’ direct analysis flow
  - Form validation and error handling
  - **Start here for**: Frontend upload logic

- **[`test_web_integration.py`](test_web_integration.py)** (260 lines)
  - Automated test suite for Phase 3
  - 5 integration tests (100% pass rate)
  - Parser, serialization, API, and UI tests
  - **Start here for**: Testing TXT parser integration

#### ğŸ†• Export System (v2.3.0)
- **[`src/exporters/markdown_exporter.py`](src/exporters/markdown_exporter.py)** (232 lines)
  - Markdown report generator
  - Jinja2 template rendering
  - Intelligent findings and recommendations
  - **Start here for**: Report generation, customization

- **[`src/exporters/mermaid_generator.py`](src/exporters/mermaid_generator.py)** (178 lines)
  - Mermaid flowchart generator
  - TCC relationship visualization
  - A/B/C line color coding
  - **Start here for**: Diagram generation, color schemes

- **[`templates/report_template.md.j2`](templates/report_template.md.j2)** (211 lines)
  - Jinja2 report template
  - Markdown structure definition
  - Customizable report layout
  - **Start here for**: Report template modification

#### Prompt System
- **[`prompts/schemas.py`](prompts/schemas.py)**
  - Pydantic models for all data structures
  - Validation functions
  - Calculation utilities
  - **Start here for**: Data models, validation logic

- **[`prompts/stage1_discoverer.md`](prompts/stage1_discoverer.md)**
  - Stage 1 prompt (TCC identification)
  - **Start here for**: Understanding TCC discovery logic

- **[`prompts/stage2_auditor.md`](prompts/stage2_auditor.md)**
  - Stage 2 prompt (A/B/C-line ranking)
  - **Start here for**: Understanding ranking criteria

- **[`prompts/stage3_modifier.md`](prompts/stage3_modifier.md)**
  - Stage 3 prompt (structural fixes)
  - **Start here for**: Understanding modification logic

- **[`prompts/README.md`](prompts/README.md)** (22,739 bytes)
  - Comprehensive prompt documentation
  - Usage patterns and examples
  - **Start here for**: Detailed prompt engineering guide

### Tests
- **[`tests/test_schemas.py`](tests/test_schemas.py)**
  - Unit tests for schemas and validators
  - **Start here for**: Schema testing patterns

- **[`tests/test_golden_dataset.py`](tests/test_golden_dataset.py)**
  - Integration tests with golden data
  - **Start here for**: End-to-end testing

- **[`benchmarks/run_benchmark.py`](benchmarks/run_benchmark.py)**
  - Performance benchmarking
  - **Start here for**: Performance testing

### Configuration
- **[`.env.example`](.env.example)** (1,374 bytes)
  - Environment variable template
  - API key configuration
  - **Copy to `.env`** and add your keys

- **[`requirements.txt`](requirements.txt)** (426 bytes)
  - Core dependencies
  - **Install with**: `pip install -r requirements.txt`

- **[`requirements-test.txt`](requirements-test.txt)** (392 bytes)
  - Test dependencies
  - **Install with**: `pip install -r requirements-test.txt`

### Documentation
- **[`README.md`](README.md)** (12,751 bytes, Chinese)
  - Main project documentation
  - Business context and theory
  - **Start here for**: Business understanding

- **[`USAGE.md`](USAGE.md)** (11,276 bytes)
  - Detailed usage guide
  - API examples
  - Troubleshooting
  - **Start here for**: Practical usage

- **[`README_DEEPSEEK.md`](README_DEEPSEEK.md)** (8,338 bytes)
  - DeepSeek integration guide
  - **Start here for**: DeepSeek setup

#### ğŸ†• Observability & Monitoring
- **[`docs/langsmith-quickstart.md`](docs/langsmith-quickstart.md)** (3 pages)
  - 5-minute LangSmith setup
  - **Start here for**: Quick observability setup

- **[`docs/langsmith-integration.md`](docs/langsmith-integration.md)** (15 pages)
  - Complete LangSmith guide
  - Configuration, usage, troubleshooting
  - **Start here for**: Full observability features

- **[`LANGSMITH_FEATURES.md`](docs/LANGSMITH_FEATURES.md)** (12 pages)
  - Technical implementation details
  - Architecture and design
  - **Start here for**: Understanding how tracing works

- **[`LANGSMITH_INTEGRATION_SUMMARY.md`](LANGSMITH_INTEGRATION_SUMMARY.md)** (11 pages)
  - Development summary
  - Completed features
  - **Start here for**: What was implemented

- **[`LANGSMITH_QUICKREF.md`](LANGSMITH_QUICKREF.md)** (1 page)
  - Quick reference card
  - **Start here for**: Command cheat sheet

#### ğŸ†• A/B Testing
- **[`docs/ab-testing-quickstart.md`](docs/ab-testing-quickstart.md)** (2 pages)
  - 3-minute A/B testing tutorial
  - **Start here for**: Quick A/B testing intro

- **[`docs/ab-testing-guide.md`](docs/ab-testing-guide.md)** (18 pages)
  - Complete A/B testing guide
  - Use cases, best practices, examples
  - **Start here for**: Comprehensive A/B testing

- **[`AB_TESTING_SUMMARY.md`](AB_TESTING_SUMMARY.md)** (10 pages)
  - A/B testing implementation summary
  - Features and architecture
  - **Start here for**: What was built

#### ğŸ†• Export & Reporting (v2.3.0)
- **[`docs/export-guide.md`](docs/export-guide.md)** (20+ pages)
  - Complete export functionality guide
  - Markdown report structure
  - Mermaid visualization usage
  - Report customization
  - **Start here for**: Generating and customizing reports

#### ğŸ†• TXT Parser Documentation (v2.4.0)
- **[`PARSER_PHASE1_COMPLETE.md`](PARSER_PHASE1_COMPLETE.md)** (15 pages)
  - Phase 1 completion report
  - Basic TXT parser implementation
  - Testing results and validation
  - **Start here for**: Understanding Phase 1 development

- **[`PARSER_PHASE2_COMPLETE.md`](PARSER_PHASE2_COMPLETE.md)** (18 pages)
  - Phase 2 completion report
  - LLM enhancement implementation
  - Prompt engineering details
  - **Start here for**: Understanding LLM enhancement

- **[`PARSER_PHASE3_COMPLETE.md`](PARSER_PHASE3_COMPLETE.md)** (25 pages)
  - Phase 3 completion report
  - Web integration implementation
  - User workflow and features
  - **Start here for**: Understanding Web integration

- **[`PHASE3_TEST_RESULTS.md`](PHASE3_TEST_RESULTS.md)** (12 pages)
  - Automated test results
  - 5/5 tests passing (100%)
  - Integration test coverage
  - **Start here for**: Testing methodology and results

- **[`DEVELOPMENT_LOG.md`](DEVELOPMENT_LOG.md)** (Session 1-6)
  - Complete development history
  - 6 development sessions documented
  - All decisions and implementations tracked
  - **Start here for**: Full development timeline

- **[`CRITICAL_GAP_ANALYSIS.md`](CRITICAL_GAP_ANALYSIS.md)** (15 pages)
  - Problem analysis (TXT vs JSON gap)
  - Solution design and alternatives
  - Decision rationale
  - **Start here for**: Understanding why TXT parser was needed

- **[`PARSER_DEVELOPMENT_PLAN.md`](PARSER_DEVELOPMENT_PLAN.md)** (20 pages)
  - 4-phase development plan
  - Technical architecture
  - Task breakdown (60+ subtasks)
  - **Start here for**: Development methodology

- **[`TASKS_SUMMARY.md`](TASKS_SUMMARY.md)**
  - Task tracking and milestones
  - Risk assessment
  - Progress monitoring
  - **Start here for**: Project management view

### Examples
- **[`examples/golden/`](examples/golden/)**
  - Golden dataset scripts for testing
  - Example: `ç™¾å¦–_ep09_s01-s05.json`
  - **Use for**: Testing and validation

---

## Common Tasks

### Task: Understand the System
1. Read [`ref/project-overview.md`](ref/project-overview.md)
2. Read [`ref/architecture.md`](ref/architecture.md)
3. Review [`README.md`](README.md) for business context

### Task: Set Up Development Environment
1. Follow [`ref/getting-started.md`](ref/getting-started.md) - Installation section
2. Configure API key using [`.env.example`](.env.example)
3. Run tests: `./run_tests.sh`

### Task: Analyze a Script (JSON)
1. Check [`USAGE.md`](USAGE.md) - "Using the Pipeline" section
2. Use CLI: `python -m src.cli analyze script.json`
3. Or use API from [`ref/api-reference.md`](ref/api-reference.md)

### Task: Parse TXT Script
1. Read [`ref/txt-parser-guide.md`](ref/txt-parser-guide.md) - TXT format requirements
2. Basic parsing:
   ```python
   from src.parser import TXTScriptParser
   parser = TXTScriptParser()
   script = parser.parse("script.txt")
   ```
3. With LLM enhancement:
   ```python
   from src.parser import LLMEnhancedParser
   from src.pipeline import create_llm
   llm = create_llm(provider="deepseek")
   parser = LLMEnhancedParser(llm=llm)
   script = parser.parse("script.txt")
   ```

### Task: Use Web UI for TXT Upload
1. Start Web server: `bash run_web_server.sh`
2. Open browser: `http://localhost:8000`
3. Select "TXT (åŸå§‹å‰§æœ¬)" file type
4. Toggle "ä½¿ç”¨ LLM è¯­ä¹‰å¢å¼º" as needed
5. Upload TXT file
6. Preview parsed results (4 tabs)
7. Click "Continue to Analysis"
8. View three-stage analysis results

### Task: Add New Feature
1. Read [`ref/architecture.md`](ref/architecture.md) - Extension Points
2. Review existing code in [`src/pipeline.py`](src/pipeline.py)
3. Follow TDD workflow from [`ref/testing.md`](ref/testing.md)
4. Update schemas in [`prompts/schemas.py`](prompts/schemas.py)

### Task: Modify Prompts
1. Read [`ref/prompts-guide.md`](ref/prompts-guide.md)
2. Edit files in [`prompts/`](prompts/) directory
3. Update [`prompts/schemas.py`](prompts/schemas.py) if needed
4. Test changes using [`tests/test_golden_dataset.py`](tests/test_golden_dataset.py)

### Task: Debug Test Failure
1. Check [`ref/testing.md`](ref/testing.md) - Troubleshooting section
2. Review test file: [`tests/test_schemas.py`](tests/test_schemas.py) or [`tests/test_golden_dataset.py`](tests/test_golden_dataset.py)
3. Run with verbose: `pytest tests/ -v -s`

### Task: Optimize Performance
1. Read [`ref/architecture.md`](ref/architecture.md) - Performance section
2. Run benchmarks: `python benchmarks/run_benchmark.py examples/golden`
3. Check [`USAGE.md`](USAGE.md) - Performance tips

### Task: Integrate New LLM Provider
1. Read [`ref/architecture.md`](ref/architecture.md) - LLM Provider Support
2. Edit [`src/pipeline.py`](src/pipeline.py) - `create_llm()` function
3. Update [`.env.example`](.env.example) with new variables
4. Test integration

### ğŸ†• Task: Enable LangSmith Tracing
1. Read [`docs/langsmith-quickstart.md`](docs/langsmith-quickstart.md) - 5-minute setup
2. Get API key from https://smith.langchain.com/
3. Update `.env`: `LANGCHAIN_TRACING_V2=true` and add API key
4. Run analysis - tracing is automatic

### ğŸ†• Task: Run A/B Test
1. Read [`docs/ab-testing-quickstart.md`](docs/ab-testing-quickstart.md) - 3-minute tutorial
2. Compare providers: `python -m src.cli ab-test script.json --providers deepseek,anthropic`
3. Compare temperatures: `python -m src.cli ab-test script.json --temperatures 0.0,0.7`
4. Review results in terminal and `ab_tests/` directory

### ğŸ†• Task: Analyze Performance Metrics
1. Run analysis with LangSmith enabled
2. Check terminal output for performance summary
3. View detailed metrics in `_metrics` field of result
4. Use `src/monitoring.py` for historical analysis

### ğŸ†• Task: Generate Report (v2.3.0)
1. Read [`docs/export-guide.md`](docs/export-guide.md) - Complete export guide
2. Analyze script with export flag: `python -m src.cli analyze script.json --export report.md`
3. View report in Markdown editor (VS Code, Obsidian, Typora)
4. Customize template in `templates/report_template.md.j2` if needed

---

## Key Concepts

### Theatrical Conflict Chain (TCC)
Independent narrative thread with super objective, forces, and evidence.
- **Details**: [`README.md`](README.md) lines 302-314
- **Schema**: [`prompts/schemas.py`](prompts/schemas.py)
- **Prompt**: [`prompts/stage1_discoverer.md`](prompts/stage1_discoverer.md)

### A/B/C-Line Classification
Ranking system for story importance (A=main, B=subplot, C=flavor).
- **Details**: [`README.md`](README.md) lines 54-68
- **Criteria**: [`ref/prompts-guide.md`](ref/prompts-guide.md) lines 164-244
- **Prompt**: [`prompts/stage2_auditor.md`](prompts/stage2_auditor.md)

### Setup-Payoff Chain
Cause-effect relationships between scenes.
- **Validation**: [`prompts/schemas.py`](prompts/schemas.py) - `validate_setup_payoff_integrity()`
- **Fixing**: [`prompts/stage3_modifier.md`](prompts/stage3_modifier.md)

### Director-Actor Pattern
LangGraph-based orchestration with specialized agents.
- **Details**: [`ref/architecture.md`](ref/architecture.md) lines 13-35
- **Implementation**: [`src/pipeline.py`](src/pipeline.py)

---

## Project Structure

```
.
â”œâ”€â”€ CLAUDE.md                    # This file - navigation guide
â”œâ”€â”€ README.md                    # Main documentation (Chinese)
â”œâ”€â”€ USAGE.md                     # Usage guide
â”œâ”€â”€ README_DEEPSEEK.md          # DeepSeek integration
â”‚
â”œâ”€â”€ ref/                         # Reference documentation
â”‚   â”œâ”€â”€ project-overview.md     # Project summary
â”‚   â”œâ”€â”€ architecture.md         # System design
â”‚   â”œâ”€â”€ getting-started.md      # Setup guide
â”‚   â”œâ”€â”€ api-reference.md        # API docs
â”‚   â”œâ”€â”€ testing.md              # Testing guide
â”‚   â””â”€â”€ prompts-guide.md        # Prompt engineering
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ pipeline.py             # Core pipeline
â”‚   â”œâ”€â”€ cli.py                  # CLI interface
â”‚   â”œâ”€â”€ parser/                 # ğŸ†• TXT Parser system (v2.4.0)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py             # Abstract parser base class
â”‚   â”‚   â”œâ”€â”€ txt_parser.py       # Basic rule-based parser (Phase 1)
â”‚   â”‚   â”œâ”€â”€ llm_enhancer.py     # LLM-enhanced parser (Phase 2)
â”‚   â”‚   â””â”€â”€ prompts/            # LLM prompts for enhancement
â”‚   â”‚       â”œâ”€â”€ scene_mission_prompt.md
â”‚   â”‚       â”œâ”€â”€ key_events_prompt.md
â”‚   â”‚       â”œâ”€â”€ setup_payoff_prompt.md
â”‚   â”‚       â”œâ”€â”€ relation_change_prompt.md
â”‚   â”‚       â””â”€â”€ info_change_prompt.md
â”‚   â”œâ”€â”€ web/                    # ğŸ†• Web UI (Phase 3)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ app.py              # FastAPI application
â”‚   â”œâ”€â”€ exporters/              # ğŸ†• Export system (v2.3.0)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ markdown_exporter.py # Markdown report generator
â”‚   â”‚   â””â”€â”€ mermaid_generator.py # Mermaid diagram generator
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ templates/                   # ğŸ†• Web UI templates
â”‚   â”œâ”€â”€ base.html               # Base layout template
â”‚   â”œâ”€â”€ index.html              # Upload page (supports JSON & TXT)
â”‚   â”œâ”€â”€ parse_preview.html      # ğŸ†• TXT parse preview (Phase 3)
â”‚   â”œâ”€â”€ analysis.html           # Three-stage analysis page
â”‚   â”œâ”€â”€ results.html            # Results display page
â”‚   â””â”€â”€ report_template.md.j2   # Jinja2 Markdown template (v2.3.0)
â”‚
â”œâ”€â”€ static/                      # ğŸ†• Web UI assets
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ custom.css          # Custom styles
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ upload.js           # Upload logic (JSON & TXT routing)
â”‚       â”œâ”€â”€ analysis.js         # Analysis page logic
â”‚       â””â”€â”€ results.js          # Results page logic
â”‚
â”œâ”€â”€ prompts/                     # Prompt system
â”‚   â”œâ”€â”€ stage1_discoverer.md    # Stage 1 prompt
â”‚   â”œâ”€â”€ stage2_auditor.md       # Stage 2 prompt
â”‚   â”œâ”€â”€ stage3_modifier.md      # Stage 3 prompt
â”‚   â”œâ”€â”€ schemas.py              # Data models
â”‚   â””â”€â”€ README.md               # Prompt guide
â”‚
â”œâ”€â”€ tests/                       # Test suites
â”‚   â”œâ”€â”€ test_schemas.py         # Unit tests
â”‚   â”œâ”€â”€ test_golden_dataset.py  # Integration tests
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ benchmarks/                  # Performance tests
â”‚   â””â”€â”€ run_benchmark.py
â”‚
â”œâ”€â”€ examples/                    # Sample data
â”‚   â”œâ”€â”€ golden/                 # Test datasets (JSON)
â”‚   â””â”€â”€ test_scripts/           # ğŸ†• TXT test scripts
â”‚       â””â”€â”€ simple_script.txt   # Example TXT script
â”‚
â”œâ”€â”€ docs/                        # Development docs
â”‚   â”œâ”€â”€ langsmith-quickstart.md
â”‚   â”œâ”€â”€ langsmith-integration.md
â”‚   â”œâ”€â”€ ab-testing-quickstart.md
â”‚   â”œâ”€â”€ ab-testing-guide.md
â”‚   â”œâ”€â”€ export-guide.md
â”‚   â”œâ”€â”€ development-plan.md
â”‚   â””â”€â”€ test-script-conversion-plan.md
â”‚
â”œâ”€â”€ .env.example                 # Environment template
â”œâ”€â”€ requirements.txt             # Core dependencies
â”œâ”€â”€ requirements-test.txt        # Test dependencies
â”œâ”€â”€ requirements-web.txt         # ğŸ†• Web UI dependencies
â”œâ”€â”€ pytest.ini                   # Pytest configuration
â”œâ”€â”€ run_tests.sh                 # Test runner script
â”œâ”€â”€ run_web_server.sh            # ğŸ†• Web server launcher
â””â”€â”€ test_web_integration.py      # ğŸ†• Phase 3 integration tests
```

---

## Environment Setup Checklist

- [x] Python 3.8+ installed âœ…
- [x] Dependencies installed: `pip install -r requirements.txt` âœ…
  - LangChain 1.0.5
  - LangGraph 1.0.3
  - Pydantic, tenacity, etc.
- [x] `.env` file created from `.env.example` âœ…
- [x] API key added to `.env` (DeepSeek) âœ…
- [x] Tests passing: `pytest tests/ -v` âœ… (44/44 passed)
- [x] Stage 1 working: `python -m src.cli analyze examples/golden/ç™¾å¦–_ep09_s01-s05.json` âœ…
- [x] Stage 2 JSON parsing fixed âœ…
- [x] Stage 3 validation fixed âœ…
- [x] Complete 3-stage pipeline end-to-end test âœ… (0 errors, 0 retries)

---

## Development Workflow

### Standard Workflow
1. Read relevant documentation from `/ref`
2. Review existing code in `/src` or `/prompts`
3. Write tests first (see [`ref/testing.md`](ref/testing.md))
4. Implement feature
5. Run tests: `pytest tests/ -v`
6. Update documentation if needed

### Prompt Modification Workflow
1. Read [`ref/prompts-guide.md`](ref/prompts-guide.md)
2. Edit prompt file in [`prompts/`](prompts/)
3. Update [`prompts/schemas.py`](prompts/schemas.py) if schema changed
4. Test with golden dataset: `pytest tests/test_golden_dataset.py -v`
5. Update [`prompts/README.md`](prompts/README.md) with changes

### Adding New Feature Workflow
1. Design: Review [`ref/architecture.md`](ref/architecture.md)
2. Test: Write tests in [`tests/`](tests/)
3. Implement: Add code to [`src/`](src/)
4. Validate: Run full test suite
5. Document: Update [`ref/api-reference.md`](ref/api-reference.md)

---

## Troubleshooting Quick Reference

### Issue: API Key Error
- **Solution**: Check [`.env`](.env) file, see [`ref/getting-started.md`](ref/getting-started.md) lines 60-96

### Issue: Test Failure
- **Solution**: See [`ref/testing.md`](ref/testing.md) lines 533-567

### Issue: Validation Error
- **Solution**: Check [`prompts/schemas.py`](prompts/schemas.py), see [`ref/api-reference.md`](ref/api-reference.md) lines 440-457

### Issue: LLM Output Format Wrong
- **Solution**: See [`ref/prompts-guide.md`](ref/prompts-guide.md) lines 645-664

### Issue: Performance Slow
- **Solution**: See [`USAGE.md`](USAGE.md) lines 445-450, [`ref/architecture.md`](ref/architecture.md) lines 336-348

### Issue: TXT Parser - No Scenes Found
- **Cause**: Scene headers not recognized
- **Solution**: See [`ref/txt-parser-guide.md`](ref/txt-parser-guide.md) - TXT Format Requirements section
- Check scene header format (S01, åœºæ™¯ 1, etc.)
- Ensure consistent formatting throughout script

### Issue: TXT Parser - Character Names Wrong
- **Cause**: False positives in character extraction
- **Solution**: Use LLM enhancement for better accuracy, or review and manually correct in preview

### Issue: TXT Parser - LLM Enhancement Slow
- **Cause**: 5 LLM calls per scene, sequential processing
- **Solution**: Disable LLM enhancement for faster basic parse, or use faster LLM model

### Issue: Web UI - Parse Preview Stuck on "Parsing in Progress..."
- **Cause**: WebSocket serialization error (Script object not JSON serializable)
- **Solution**: Fixed in Session 7 - WebSocket now sends summary stats instead of full Script object
- **Workaround**: Polling fallback mechanism automatically activates if WebSocket fails
- **Files**: `src/web/app.py:408-449, 490-497`, `templates/parse_preview.html:194-238`

### Issue: Web UI - Upload Page Not Redirecting After TXT Upload
- **Cause**: Browser caching old JavaScript, or JavaScript error preventing redirect
- **Solution**:
  1. Hard refresh browser (Ctrl+Shift+R or Cmd+Shift+R)
  2. Open browser DevTools Console (F12)
  3. Check for errors in console
  4. Verify debug logs show "Redirecting to: /parse-preview/..."
- **Files**: `static/js/upload.js:104-122` (debug logs added in Session 7)

### Issue: Web UI - WebSocket Connection Failed
- **Cause**: Network issues or browser compatibility
- **Solution**:
  - Check browser console for WebSocket errors
  - Polling fallback will automatically activate (every 2 seconds)
  - Try different browser
  - Check firewall settings

---

## External Resources

### LLM Providers
- DeepSeek: https://platform.deepseek.com/
- Anthropic Claude: https://console.anthropic.com/
- OpenAI: https://platform.openai.com/

### Technical Documentation
- LangChain: https://python.langchain.com/docs/
- LangGraph: https://langchain-ai.github.io/langgraph/
- LangSmith: https://docs.smith.langchain.com/
- Pydantic: https://docs.pydantic.dev/
- pytest: https://docs.pytest.org/

### Narrative Theory
- Robert McKee - "Story": Narrative structure principles
- "The Art of Dramatic Writing": Multi-line storytelling

---

## Version Information

**Project Version**: 2.4.1 (Session 8: UX Optimization + Mermaid Visualization + Async Parser)
**Prompt Version**: 2.1-Refactored + Auto-Merge + TXT Parser Prompts
**Documentation Version**: 1.7 (Added Session 8 UX optimization and bug fixes)
**Last Updated**: 2025-11-14
**Latest Commit**: TBD (feat: Session 8 - fix Mermaid visualization, async parser, and issue_id validation)
**Completion Status**: 100% (All stages + TXT Parser + Web UI + Mermaid Visualization + observability + A/B testing + export - Production Ready)

---

## Contact & Support

- **Documentation Issues**: Review this file and linked docs
- **Code Issues**: Check [`tests/`](tests/) for examples
- **Prompt Issues**: See [`prompts/README.md`](prompts/README.md)
- **API Questions**: See [`ref/api-reference.md`](ref/api-reference.md)

---

## Notes for AI Assistants

### When Helping with This Project:

1. **Always start by reading**:
   - This file (CLAUDE.md) for navigation
   - [`ref/project-overview.md`](ref/project-overview.md) for context
   - [`ref/architecture.md`](ref/architecture.md) for design

2. **For specific tasks, consult**:
   - API questions â†’ [`ref/api-reference.md`](ref/api-reference.md)
   - Testing â†’ [`ref/testing.md`](ref/testing.md)
   - Prompts â†’ [`ref/prompts-guide.md`](ref/prompts-guide.md)
   - Setup â†’ [`ref/getting-started.md`](ref/getting-started.md)

3. **Code locations**:
   - Pipeline logic: [`src/pipeline.py`](src/pipeline.py)
   - Data models: [`prompts/schemas.py`](prompts/schemas.py)
   - Prompts: [`prompts/stage*.md`](prompts/)
   - TXT Parser: [`src/parser/`](src/parser/)
   - Web UI: [`src/web/app.py`](src/web/app.py)

4. **Testing approach**:
   - Unit tests: [`tests/test_schemas.py`](tests/test_schemas.py)
   - Integration: [`tests/test_golden_dataset.py`](tests/test_golden_dataset.py)
   - TXT Parser tests: [`test_web_integration.py`](test_web_integration.py)
   - Examples: [`examples/golden/`](examples/golden/) and [`examples/test_scripts/`](examples/test_scripts/)

5. **This project uses**:
   - Python 3.8+
   - DeepSeek as default LLM (most cost-effective)
   - LangGraph for orchestration
   - Pydantic for validation
   - pytest for testing

---

**This file was generated by**: /initref command
**Purpose**: Provide quick navigation and context for AI-assisted development
**Maintenance**: Update when adding new features or documentation
