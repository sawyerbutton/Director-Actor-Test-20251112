# Environment Configuration for Script Analysis System
# Copy this file to .env and fill in your API keys

# ============================================================================
# LLM Provider Configuration
# ============================================================================

# DeepSeek (Default Provider)
# Get your API key from: https://platform.deepseek.com/
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# Anthropic Claude (Optional)
# Get your API key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI (Optional)
# Get your API key from: https://platform.openai.com/
# OPENAI_API_KEY=your_openai_api_key_here

# Google Gemini API Keys
# Get your API key from: https://aistudio.google.com/app/apikey

# Gemini 2.5 Flash (Legacy - for backward compatibility)
# Features: 1M context, 65K output
# GOOGLE_API_KEY=your_google_api_key_here

# Gemini 3 Pro (Recommended for large scripts)
# Features: 1M context, 64K output, advanced reasoning capabilities
# Reference: https://ai.google.dev/gemini-api/docs/gemini-3
# Note: If set, this key will be used for Gemini 3 Pro; otherwise falls back to GOOGLE_API_KEY
# GOOGLE_GEMINI3_API_KEY=your_gemini3_api_key_here

# ============================================================================
# Pipeline Configuration
# ============================================================================

# Default LLM provider (deepseek, anthropic, openai, or gemini)
LLM_PROVIDER=deepseek

# Default model for each provider
# DEEPSEEK_MODEL=deepseek-chat
# ANTHROPIC_MODEL=claude-sonnet-4-5
# OPENAI_MODEL=gpt-4-turbo-preview
# GEMINI_MODEL=gemini-3-pro-preview

# ============================================================================
# Logging Configuration
# ============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ============================================================================
# LangSmith Configuration (Observability & Monitoring)
# ============================================================================

# Enable LangSmith tracing (true/false)
# Set to true to enable automatic tracing of all LLM calls and pipeline execution
LANGCHAIN_TRACING_V2=false

# LangSmith API Key
# Get your API key from: https://smith.langchain.com/settings
# Format: ls__xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
LANGCHAIN_API_KEY=your_langsmith_api_key_here

# LangSmith Project Name
# Used to organize runs in LangSmith dashboard
# Recommended naming: {app}-{environment} (e.g., screenplay-analysis-dev)
LANGCHAIN_PROJECT=screenplay-analysis-dev

# LangSmith Endpoint (optional, uses default if not set)
# Only change this if using self-hosted LangSmith
# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
